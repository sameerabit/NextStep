2023.07.09 14:26:10 INFO  es[][o.e.n.Node] version[8.7.0], pid[99], build[tar/09520b59b6bc1057340b55750186466ea715e30e/2023-03-27T16:31:09.816451435Z], OS[Linux/5.15.49-linuxkit/aarch64], JVM[Eclipse Adoptium/OpenJDK 64-Bit Server VM/17.0.7/17.0.7+7]
2023.07.09 14:26:10 INFO  es[][o.e.n.Node] JVM home [/opt/java/openjdk], using bundled JDK [false]
2023.07.09 14:26:10 INFO  es[][o.e.n.Node] JVM arguments [-Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -Djava.security.manager=allow, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/opt/sonarqube/temp, -XX:ErrorFile=/opt/sonarqube/logs/es_hs_err_pid%p.log, -Xlog:disable, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djna.tmpdir=/opt/sonarqube/temp, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=COMPAT, -Dcom.redhat.fips=false, -Des.enforce.bootstrap.checks=true, -Xmx512m, -Xms512m, -XX:MaxDirectMemorySize=256m, -XX:+HeapDumpOnOutOfMemoryError, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.distribution.type=tar, --module-path=/opt/sonarqube/elasticsearch/lib, --add-modules=jdk.net, -Djdk.module.main=org.elasticsearch.server]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [aggregations]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [analysis-common]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [apm]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [blob-cache]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [lang-painless]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [old-lucene-versions]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [parent-join]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [reindex]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [transport-netty4]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [x-pack-aggregate-metric]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [x-pack-core]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [x-pack-profiling]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] loaded module [x-pack-security]
2023.07.09 14:26:12 INFO  es[][o.e.p.PluginsService] no plugins loaded
2023.07.09 14:26:14 INFO  es[][o.e.e.NodeEnvironment] using [1] data paths, mounts [[/opt/sonarqube/data (grpcfuse)]], net usable_space [41.5gb], net total_space [228.2gb], types [fuse.grpcfuse]
2023.07.09 14:26:14 INFO  es[][o.e.e.NodeEnvironment] heap size [512mb], compressed ordinary object pointers [true]
2023.07.09 14:26:14 INFO  es[][o.e.n.Node] node name [sonarqube], node ID [k3Ismz0IQxylLUnLqJAAew], cluster name [sonarqube], roles [ingest, data_frozen, ml, data_hot, transform, data_content, data_warm, master, remote_cluster_client, data, data_cold]
2023.07.09 14:26:15 INFO  es[][o.e.x.p.ProfilingPlugin] Profiling is enabled
2023.07.09 14:26:15 INFO  es[][o.e.x.s.Security] Security is disabled
2023.07.09 14:26:16 INFO  es[][o.e.t.n.NettyAllocator] creating NettyAllocator with the following configs: [name=unpooled, suggested_max_allocation_size=1mb, factors={es.unsafe.use_unpooled_allocator=null, g1gc_enabled=true, g1gc_region_size=4mb, heap_size=512mb}]
2023.07.09 14:26:16 INFO  es[][o.e.i.r.RecoverySettings] using rate limit [40mb] with [default=40mb, read=0b, write=0b, max=0b]
2023.07.09 14:26:16 INFO  es[][o.e.d.DiscoveryModule] using discovery type [single-node] and seed hosts providers [settings]
2023.07.09 14:26:16 INFO  es[][o.e.n.Node] initialized
2023.07.09 14:26:16 INFO  es[][o.e.n.Node] starting ...
2023.07.09 14:26:16 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:39643}, bound_addresses {127.0.0.1:39643}
2023.07.09 14:26:17 INFO  es[][o.e.b.BootstrapChecks] explicitly enforcing bootstrap checks
2023.07.09 14:26:17 WARN  es[][o.e.c.c.ClusterBootstrapService] this node is locked into cluster UUID [oMEdOrFyRPWGLF8wMZTmHg] but [cluster.initial_master_nodes] is set to [sonarqube]; remove this setting to avoid possible data loss caused by subsequent cluster bootstrap attempts; for further information see https://www.elastic.co/guide/en/elasticsearch/reference/8.7/important-settings.html#initial_master_nodes
2023.07.09 14:26:17 INFO  es[][o.e.c.s.MasterService] elected-as-master ([1] nodes joined)[_FINISH_ELECTION_, {sonarqube}{k3Ismz0IQxylLUnLqJAAew}{Euxvl89ITuqN4zCF9KZt9w}{sonarqube}{127.0.0.1}{127.0.0.1:39643}{cdfhilmrstw}{8.7.0} completing election], term: 17, version: 371, delta: master node changed {previous [], current [{sonarqube}{k3Ismz0IQxylLUnLqJAAew}{Euxvl89ITuqN4zCF9KZt9w}{sonarqube}{127.0.0.1}{127.0.0.1:39643}{cdfhilmrstw}{8.7.0}]}
2023.07.09 14:26:17 INFO  es[][o.e.c.s.ClusterApplierService] master node changed {previous [], current [{sonarqube}{k3Ismz0IQxylLUnLqJAAew}{Euxvl89ITuqN4zCF9KZt9w}{sonarqube}{127.0.0.1}{127.0.0.1:39643}{cdfhilmrstw}{8.7.0}]}, term: 17, version: 371, reason: Publication{term=17, version=371}
2023.07.09 14:26:17 INFO  es[][o.e.r.s.FileSettingsService] starting file settings watcher ...
2023.07.09 14:26:17 INFO  es[][o.e.r.s.FileSettingsService] file settings service up and running [tid=34]
2023.07.09 14:26:17 INFO  es[][o.e.h.AbstractHttpServerTransport] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}
2023.07.09 14:26:17 INFO  es[][o.e.c.c.NodeJoinExecutor] node-join: [{sonarqube}{k3Ismz0IQxylLUnLqJAAew}{Euxvl89ITuqN4zCF9KZt9w}{sonarqube}{127.0.0.1}{127.0.0.1:39643}{cdfhilmrstw}{8.7.0}] with reason [completing election]
2023.07.09 14:26:17 INFO  es[][o.e.n.Node] started {sonarqube}{k3Ismz0IQxylLUnLqJAAew}{Euxvl89ITuqN4zCF9KZt9w}{sonarqube}{127.0.0.1}{127.0.0.1:39643}{cdfhilmrstw}{8.7.0}{rack_id=sonarqube, xpack.installed=true}
2023.07.09 14:26:17 INFO  es[][o.e.l.LicenseService] license [4677d80f-b372-4993-a285-ee376af944fc] mode [basic] - valid
2023.07.09 14:26:17 INFO  es[][o.e.g.GatewayService] recovered [6] indices into cluster_state
2023.07.09 14:26:18 INFO  es[][o.e.h.n.s.HealthNodeTaskExecutor] Node [{sonarqube}{k3Ismz0IQxylLUnLqJAAew}] is selected as the current health node.
2023.07.09 14:26:20 INFO  es[][o.e.c.r.a.AllocationService] current.health="GREEN" message="Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[metadatas][0]]])." previous.health="RED" reason="shards started [[metadatas][0]]"
2023.07.09 14:47:48 INFO  es[][o.e.m.j.JvmGcMonitorService] [gc][1288] overhead, spent [255ms] collecting in the last [1s]
2023.07.09 15:07:55 WARN  es[][o.e.t.ThreadPool] timer thread slept for [52.7s/52760ms] on absolute clock which is above the warn threshold of [5000ms]
2023.07.09 15:09:33 WARN  es[][o.e.t.ThreadPool] timer thread slept for [38.9s/38911ms] on absolute clock which is above the warn threshold of [5000ms]
2023.07.09 15:10:51 WARN  es[][o.e.t.ThreadPool] timer thread slept for [47.5s/47534ms] on absolute clock which is above the warn threshold of [5000ms]
2023.07.09 15:12:38 WARN  es[][o.e.t.ThreadPool] timer thread slept for [47.3s/47378ms] on absolute clock which is above the warn threshold of [5000ms]
2023.07.09 15:14:00 WARN  es[][o.e.t.ThreadPool] timer thread slept for [51.8s/51887ms] on absolute clock which is above the warn threshold of [5000ms]
2023.07.09 15:30:59 WARN  es[][o.e.t.ThreadPool] timer thread slept for [15.9m/959126ms] on absolute clock which is above the warn threshold of [5000ms]
2023.07.09 15:38:54 INFO  es[][o.e.n.Node] stopping ...
2023.07.09 15:38:54 INFO  es[][o.e.r.s.FileSettingsService] shutting down watcher thread
2023.07.09 15:38:54 INFO  es[][o.e.r.s.FileSettingsService] watcher service stopped
2023.07.09 15:38:55 INFO  es[][o.e.n.Node] stopped
2023.07.09 15:38:55 INFO  es[][o.e.n.Node] closing ...
2023.07.09 15:38:55 INFO  es[][o.e.n.Node] closed
